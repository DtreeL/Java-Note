# SQL

## DDL

(Date Definition Language)数据定义语言：如建库，建表

### 库

创建数据库

```sql
CREATE DATABASE [IF NOT EXISTS] 数据库名;
CREATE DATABASE 数据库名 character set 字符集;
```

查看数据库

```sql
SHOW DATABASES [LIKE "筛选条件"];
show databases;--查看所有数据库
show create database 数据库名;--查看数据库的定义信息
select database();--查看正在使用的数据库
```

修改数据库

```sql
alter database 数据库名 default character set 字符集;
```

使用数据库

```sql
use 数据库名;
```

删除数据库

```sql
drop database 数据库名;
```

### 表(前提是先使用某个数据库)

创建表

```sql
create table 表名(
    --int double varchar()可变字符串 date日期类型，无时分秒
    --primary key设置为主键,auto_increment代表自增
	字段名1 字段类型1 primary key auto_increment，
  
    --unique唯一约束，代表这一列不能出现同名，null没有数据不存在相不相同的问题
    --not null
    --default 默认值
    字段名2 字段类型2 unique，
    ...
    --最后一个结尾没有逗号
    字段名n，字段类型n
)auto_increment=自增的起始值;

--创建的表1结构跟表2一样
create table 表1 like 表2;

添加外键
FOREIGN KEY 字段1 字段2..... REFERENCES 主表 字段1 字段2......
```

查看表

```sql
show tables;

desc 表名;--查看表结构
```

删除表

```sql
drop table 表名;
drop if exist 表名;
```

修改表

```sql
alter table 表名 add 列名 类型;
alter table 表名 modify 列名 新的类型;
alter table 表名 change 旧列名 新列名 类型;
alter table 表名 drop 列名;--删除列

rename table 表名 to 新表名;

alter table 表名 character set 字符集;
alter table 表名 add primary key(字段名)；--修改字段为主键
alter table 表名 auto_increment=起始值;--创建好表后修改起始值
ALTER TABLE 表名 ADD FOREIGN KEY 外键字段名 REFERENCES 主表名 主表字段;
ALTER TABLE 表名 DROP FOREIGN KEY 外键字段名
```

## DML

(Date Manipulation Language)数据操纵语言：记录操作增删改

```sql
--插入
insert into 表名(
	字段名1，字段名2，字段名3，...--不写字段名默认全部
)
values(
	值1，值2，值3，...--值对应不上上面的字段，会使用null，字符型和日期要用引号
);
insert into 表名1(列1，列2) select 列1，列2 from 表名2;--复制表
insert ignore into
	会忽略数据库中已经存在的数据，如果数据库没有数据，就插入新的数据，如果有数据的话就跳过这条数据。
--更新
update 表名 set 列名=值 where 条件表达式;--不写条件为所有修改

--删除，对自增长没有影响
delete from 表名 where 条件表达式;

truncate table 表名;--删除该表再建一空表
```

## DQL

(Data Query Language)数据查询语言

and比or的执行优先级高

```sql
select * from 表名;
select 字段1 as 别名，字段2，... from 表名 as 别名;--显示的时候显示别名
select distinct 字段名 from 表名;--清除字段重复值
select 列名1+固定值/列名2 from 表名;--查询的结果是参与运算后的结果

where 条件查询
<>--不等于符号
between 100 and 200 --一个范围内，包括100和200
in(,)
like '张%'--模糊查询，%匹配任意字符，_匹配一个字符
is null

逻辑运算符 and or not

--排序查询,写在where后
order by 字段名1 asc/desc，字段名2 asc/desc，...;--默认asc升序，字段1相同的数据再按照字段2排序

--分页查询
--limit 指定查询结果的行数 
LIMIT 3 OFFSET 3;
/*
分页查询的关键在于，首先要确定每页需要显示的结果数量pageSize（这里是3），然后根据当前页的索引pageIndex（从1开始），确定LIMIT和OFFSET应该设定的值：

LIMIT=pageSize；
OFFSET计算公式为pageSize * (pageIndex - 1)。
这样就能正确查询出第N页的记录集。
*/

--聚合函数,对列进行操作，返回列值，会忽略null
max(列名)
min(列名)
avg(列名)
count(列名)--计算这一列有多少条记录
count(ifnull(id,0))--不忽略null

sum(列名)

--分组查询，按字段进行分组
group by 字段 having 条件;--having分组后再条件过滤


```

### 多表查询

```java
A表 
	id name
	1  张三
	2  李四
	3  王五

B表
	id  a_id  class
	1   4     班级1
	2   2     班级2
```

内连接：只返回两个表都有，而且id相等的值

```sql
SELECT 字段集 FROM 表1 INNER JOIN 表2 ON 连接条件;

select A.name,B.class from A a  inner join B b on a.id=b.a_id

李四  班级2
```

左连接：返回包括左表所有记录，还有和右表中相等的记录

```sql
SELECT 字段集 FROM 表1 LEFT JOIN 表2 ON 连接条件;

select a.name,b.job from A a  left join B b on a.id=b.A_id

张三 null   李四  班级2   王五  null

返回A表所有的数据，没有在B表匹配的直接用null
```

右连接：返回包括右表所有记录，还有和左表中相等的记录

```java
SELECT 字段集 FROM 表1 RIGHT JOIN 表2 ON 连接条件;
```

![](https://gitee.com/DtreeL/Image-Hosting-Service/raw/master/img/20200516145800.png)

分组查询

```sql
SELECT 字段名 [聚合函数] FROM 表名 GROUP BY 字段名  [ASC | DESC] ;

select name,cout(*) as totle
from stu
group by class_id;
having count(name) > 1;

--查询所有在一个班级的同学姓名和人数,having设置条件
```

正则

| 选项        | 说明                                                      |
| :---------- | :-------------------------------------------------------- |
| ^           | 匹配文本的开始字符，如^a，就会匹配ads、alr、aea等         |
| $           | 匹配文本的结束字符                                        |
| .           | 匹配任何单个字符，如b.t，可以匹配bit、bat、but等等        |
| *           | 匹配0个或者多个在它前面的字符，如f*n。fn、fan、fasardsn等 |
| +           | 匹配前面的字符1次或者多次，如ba+，b后面至少紧跟一个a      |
| [字符集合]  | 匹配字符集任何一个字符，如[ab]，匹配a或者b的一个          |
| [^字符集合] | 匹配不在字符集的任何字符                                  |
| 字符串{n}   | 匹配前面的字符至少n次，如b{3},至少bbbb、bbbbb             |

## DCL

(Data Control Language)数据控制语言：权限设定

电脑上有多个项目的数据库

```sql
--查询用户
use myql;--切换到mysql数据库
select * from user;--查询用户表

--添加删除用户
create user '用户名'@'主机名' identified by '密码';--主机名表示该用户可以在哪个主机登录
drop use '用户名'@'主机名';

--授予/撤销用户权限
show grants for '用户名'@'主机名'；--查询权限
grant 权限列表 on 数据库.表名 to '用户名'@'主机名';--授予权限,通配符权限all 库和表*
revoke 权限列表 on 数据库.表名 to '用户名'@'主机名';--撤销权限
```

# 事务

事务又叫做TCL，全称是transaction control language

**A（原子性Atomicity）：原子性指的是事务是一个不可分割的，要么都执行要么都不执行。**

**C（一致性Consistency）：事务必须使得数据库从一个一致性状态，到另外一个一致性状态。**

**I（隔离性Isolation）：指的是一个事务的执行，不能被其他的事务所干扰。**

**D（持久性Durability）：持久性指的是一个事务一旦提交了之后，对数据库的改变就是永久的。**

隐式的事务很简单，比如我们的insert、delete、update、select这些语句都是隐式的事务。

显示的事务

```sql
步骤一：禁用步骤提交功能
set autocommit = 0；

步骤二：开启一个事务
start transaction；

步骤三：sql语句
update table user set money=500 where name = "张三"；
update table user set money=1500 where name = "李四"；

步骤四：结束事务
commit（提交）或者是rollback（回滚）。如果确定我们的语句没有问题，那么我们就可以commit，如果认为我们的语句有问题，那就rollback。
```

| Isolation Level              | 脏读（Dirty Read） | 不可重复读（Non Repeatable Read） | 幻读（Phantom Read） |
| :--------------------------- | :----------------- | :-------------------------------- | :------------------- |
| Read Uncommitted             | Yes                | Yes                               | Yes                  |
| Read Committed               | -                  | Yes                               | Yes                  |
| Repeatable Read（MySQL默认） | -                  | -                                 | Yes                  |
| Serializable                 | -                  | -                                 | -                    |

脏读

- 一个事务会读到另一个事务更新后但未提交的数据，如果读了数据后对方回滚，那么当前事务读到的数据就是脏数据，这就是脏读（Dirty Read），转账显示到帐，回滚后钱消失了

不可重复读

- 在一个事务内，多次读同一数据，在这个事务还没有结束时，如果另一个事务恰好修改了这个数据，那么，在第一个事务中，两次读取的数据就可能不一致。
- 在一个事务内读取两次同一个数据，竟然不一样

幻读

- 在一个事务中，第一次查询某条记录，发现没有，但是，当试图更新这条不存在的记录时，竟然能成功，并且，再次读取同一条记录，它就神奇地出现了
- 事务B在第3步第一次读取`id=99`的记录时，读到的记录为空，说明不存在`id=99`的记录。随后，事务A在第4步插入了一条`id=99`的记录并提交。事务B在第6步再次读取`id=99`的记录时，读到的记录仍然为空，但是，事务B在第7步试图更新这条不存在的记录时，竟然成功了，并且，事务B在第8步再次读取`id=99`的记录时，记录出现了。
- 可见，幻读就是没有读到的记录，以为不存在，但其实是可以更新成功的，并且，更新成功后，再次读取，就出现了。

# 视图

从每一个班级里面筛选出几个优秀的同学去参加考试。这时候每一个班级就可以当做是一张真实的表，很多班级筛选出来的这些同学就可以临时组成一个班级，这个班级就可以当做一个视图，也就是说，这个班级其实不是真实存在的，当考试过后，这些学生还是各回各家各找各妈。

通常情况下，视图是为了封装一些复杂的操作或者是一些重复的操作。比如说在多个地方使用相同的查询结果，再或者是sql语句比较复杂，封装成视图，下一次直接使用即可。

**创建视图：**

- create view 视图名 as select 字段名称 from 表名……;

**查看视图：**

（1）describe 视图名;

（2）show table status like '视图名'\G;

（3）show create view 视图名;

（4）select * from information_schema.views;

**修改视图：**

- create  view 视图名 as select 字段名称 from 表名……. ;

- alter   view 视图名 as select 字段名称 from 表名……;

**更新视图：**

（1）update 视图名 set 字段名=值;

（2）insert into 表名 values(值，值…);

（3）delete from 视图名 where 字段=值;

**删除视图：**

drop view if exists 视图名;

# MySQL逻辑架构

![](https://gitee.com/DtreeL/Image-Hosting-Service/raw/master/img/20200516153022.png)

最上层：连接处理、授权认证、安全

第二层：查询解析、分析、优化、缓存以及所有的内置函数，所有跨存储引擎的功能都在这里实现：存储过程、触发器、视图等

- 先查询缓存，如果缓存有，那就直接拿出来返回。如果没有那就解析器解析，然后优化器优化

第三层：存储引擎负责MySQL数据的存储和提取，**存储引擎不会去解析SQL**

| 功能         | MylSAM | MEMORY | InnoDB | Archive |
| :----------- | :----- | :----- | :----- | :------ |
| 存储限制     | 256TB  | RAM    | 64TB   | None    |
| 支持事务     | No     | No     | Yes    | No      |
| 支持全文索引 | Yes    | No     | No     | No      |
| 支持树索引   | Yes    | Yes    | Yes    | No      |
| 支持哈希索引 | No     | Yes    | No     | No      |
| 支持数据缓存 | No     | N/A    | Yes    | No      |
| 支持外键     | No     | No     | Yes    | No      |

总结

- MyISAM不支持事务、哈希索引、数据缓存、外键，但支持全文索引
- InnoDB不支持全文索引和哈希索引
- 只有MyISAM支持全文检索
- 只有InnoDB支持事务、外键
- 只有MEMORY支持哈希索引

# MySQL变量

## 系统变量

查看：`show global variables;`

**查看某个指定的系统变量**：select @@global.变量名称

- 查看会话变量值只需要global改为session

**为某个变量赋值**

- set global | session 系统变量名 = 新值；

- set @@global | @@session.系统变量名 = 值；

## 自定义变量

用户变量

- 用户变量的作用域是当前会话，也就是说你再新建一个终端或者是命令行窗口就无效了。

```sql
set @用户变量名 = 值
set @用户变量名 := 值
select @用户变量名：=值

--赋值并查看
select 字段 into 自定义变量 from 表名；
```

局部变量

- 作用域就是在定义他的begin end中有效。

```sql
declare 变量名 类型；
declare 变量名 类型 default 默认值；

set @用户变量名 = 值
set @用户变量名 := 值
select @用户变量名：=值
select 字段 into 自定义变量 from 表名；

select 局部变量名;
```

# JDBC（Java Database Connectivity）

> Java代码并不是直接通过TCP连接去访问数据库，而是通过JDBC接口来访问，而JDBC接口则通过JDBC驱动来实现真正对数据库的访问。

访问某个具体的数据库，我们只需要引入该厂商提供的JDBC驱动，就可以通过JDBC接口来访问

- 我们把某个数据库实现了JDBC接口的jar包称为JDBC驱动。

## Connection

Connection代表一个JDBC连接，它相当于Java程序到数据库的连接（通常是TCP连接）。

- 打开一个Connection时，需要准备URL、用户名和口令，才能成功连接到数据库。

```java
// 获取连接
Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)
```

```java
try (Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)) {
    try (PreparedStatement ps = conn.prepareStatement("SELECT id, grade, name, gender FROM students WHERE gender=? AND grade=?")) {
        ps.setObject(1, "M"); // 注意：索引从1开始
        ps.setObject(2, 3);
        try (ResultSet rs = ps.executeQuery()) {
            while (rs.next()) {
                long id = rs.getLong("id");
                long grade = rs.getLong("grade");
                String name = rs.getString("name");
                String gender = rs.getString("gender");
            }
        }
    }
}
```

| SQL数据类型   | Java数据类型             |
| :------------ | :----------------------- |
| BIT, BOOL     | boolean                  |
| INTEGER       | int                      |
| BIGINT        | long                     |
| REAL          | float                    |
| FLOAT, DOUBLE | double                   |
| CHAR, VARCHAR | String                   |
| DECIMAL       | BigDecimal               |
| DATE          | java.sql.Date, LocalDate |
| TIME          | java.sql.Time, LocalTime |

## JDBC Batch

SQL数据库对SQL语句相同，但只有参数不同的若干语句可以作为batch执行，即批量执行，这种操作有特别优化，速度远远快于循环执行每个SQL。

- 需要对同一个`PreparedStatement`反复设置参数并调用`addBatch()`，这样就相当于给一个SQL加上了多组参数，相当于变成了“多行”SQL。
- 调用的不是`executeUpdate()`，而是`executeBatch()`，因为我们设置了多组参数，相应地，返回结果也是多个`int`值，因此返回类型是`int[]`，循环`int[]`数组即可获取每组参数执行后影响的结果数量。

## JDBC连接池

为了避免频繁地创建和销毁JDBC连接，我们可以通过连接池（Connection Pool）复用已经创建好的连接。

- JDBC连接池有一个标准的接口`javax.sql.DataSource`

常用的JDBC连接池有：

- HikariCP
- C3P0
- BoneCP
- Druid

目前使用最广泛的是HikariCP。

---

语法不同：PreparedStatement可以使用预编译的sql，而Statment只能使用静态的sql

效率不同：PreparedStatement可以使用sql缓存区，效率比Statment高

安全性不同：PreparedStatement可以有效防止sql注入，而Statment不能防止sql注入。

# 存储引擎对比

## MyISAM

使用这个存储引擎，每个MyISAM在磁盘上存储成三个文件。

（1）frm文件：存储表的定义数据

（2）MYD文件：存放表具体记录的数据

（3）MYI文件：存储索引

MYI文件用来存储索引，但仅保存记录所在页的指针，索引的结构是B+树结构

# MySQL如何保证原子操作

MySQL里边还有几种常见的`log`，分别为：

- `undo log`
- `binlog`
- `redo log`

## bin log

无论MySQL使用什么引擎都会产生

**用户检索的出来数据是走搜索引擎的**，所以**数据库的变更，搜索引擎的数据也需要变更**

- 于是，我们就会监听`binlog`的变更，如果`binlog`有变更了，那我们就需要将变更写到对应的数据源。

---

`binlog`记录了数据库表结构和表数据变更，存储着每条变更的`SQL`语句

因为`binlog`记录了数据库表的变更，所以我们可以用`binlog`进行复制（主从复制)和恢复数据。

## redo log

> `redo log`是MySQL的InnoDB引擎所产生的。

Mysql的基本存储结构是**页**(记录都存在页里边)，所以MySQL是先把这条记录所在的**页**找到，然后把该页加载到内存中，将对应记录进行修改。

**如果在内存中把数据改了，还没来得及落磁盘，而此时的数据库挂了怎么办**？每个请求都需要将数据**立马**落磁盘之后，那速度会很慢

- 内存写完了，然后会写一份`redo log`，这份`redo log`记载着这次**在某个页上做了什么修改**。
- 写`redo log`的时候，也会有`buffer`，是先写`buffer`，再真正落到磁盘中的。

---

redo log使用顺序IO（顺序IO比随机IO快非常多）

修改的时候，写完内存了，但数据还没真正写到磁盘的时候，数据库挂了，可以根据`redo log`来对数据进行恢复。因为`redo log`是顺序IO，所以**写入的速度很快**，并且`redo log`记载的是物理变化（xxxx页做了xxx修改），文件的体积很小，**恢复速度很快**。

---

`binlog`记载的是`update/delete/insert`这样的SQL语句，而`redo log`记载的是物理修改的内容（xxxx页修改了xxx）。

`redo log`的作用是为**持久化**而生的。写完内存，如果数据库挂了，那我们可以通过`redo log`来恢复内存还没来得及刷到磁盘的数据，将`redo log`加载到内存里边，那内存就能恢复到挂掉之前的数据了。

---

`redo log`**事务开始**的时候，就开始记录每次的变更信息，而`binlog`是在**事务提交**的时候才记录。

- 写`redo log`失败了，那我们就认为这次事务有问题，回滚，不再写`binlog`
- 写`redo log`成功了，写`binlog`，写`binlog`写一半了，但失败了怎么办？我们还是会对这次的**事务回滚**，将无效的`binlog`给删除（因为`binlog`会影响从库的数据，所以需要做删除操作）
- 写`redo log`和`binlog`都成功了，那这次算是事务才会真正成功。

## 保证redo log与bin log的一致性

- 阶段1：InnoDB`redo log` 写盘，InnoDB 事务进入 `prepare` 状态
- 阶段2：`binlog` 写盘，InooDB 事务进入 `commit` 状态
  - 每个事务`binlog`的末尾，会记录一个 `XID event`，标志着事务是否提交成功，也就是说，恢复过程中，`binlog` 最后一个 XID event 之后的内容都应该被 purge。

## undo log

作用：回滚和多版本控制(MVCC)

在数据修改的时候，不仅记录了`redo log`，还记录`undo log`，如果因为某些原因导致事务失败或回滚了，可以用`undo log`进行回滚

`undo log`主要存储的也是逻辑日志

`undo log`存储着修改之前的数据，相当于一个**前版本**，MVCC实现的是读写不阻塞，读的时候只要返回前一个版本的数据就行了。

# 索引

**索引可以加快数据库的检索速度**

**索引会降低**插入、删除、修改等维护任务的速度

索引需要**占物理和数据空间**

Mysql支持Hash索引和B+树索引两种

---

各个数据页**可以组成一个**双向链表

而**每个数据页中的记录**又可以组成一个**单向**链表

- 里边儿的记录会生成一个**页目录**，在通过**主键**查找某条记录的时候可以在页目录中使用**二分法快速定位**到对应的槽
- 以**其他列**(非主键)作为搜索条件：只能从最小记录开始**依次遍历单链表中的每条记录**。

---

无优化的sql

- 定位到记录所在的页
- 需要遍历双向链表，找到所在的页
- 从所在的页内中查找相应的记录
- 由于不是根据主键查询，只能遍历所在页的单链表了

![](https://gitee.com/DtreeL/Image-Hosting-Service/raw/master/img/20200517123933.png)

底层结构就是**B+树**，B+树作为树的一种实现，能够让我们**很快地**查找出对应的记录

**要维持平衡树，就必须做额外的工作**。正因为这些额外的工作**开销**，导致索引会降低增删改的速度

## 哈希索引

哈希索引就是采用一定的**哈希算法**，把键值换算成新的哈希值，只需一次哈希算法即可**立刻定位到相应的位置，速度非常快**。

- 哈希索引也没办法利用索引完成**排序**
- 不支持**最左匹配原则**
- 在有大量重复键值情况下，哈希索引的效率也是极低的---->**哈希碰撞**问题。
- **不支持范围查询**

## 聚集和非聚集索引

聚集索引就是以**主键**创建的索引

非聚集索引（二级索引）就是以**非主键**创建的索引

- 聚集索引在叶子节点存储的是**表中的数据**
- 非聚集索引在叶子节点存储的是**主键和索引列**
- 使用非聚集索引查询出数据时，**拿到叶子上的主键再去查到想要查找的数据**。(拿到主键再查找这个过程叫做**回表**)
- **创建多个单列(非聚集)索引的时候，会生成多个索引树**(所以过多创建索引会占用磁盘空间)

覆盖索引就是把要**查询出的列和索引是对应的**，不做回表操作

---

## 最左匹配原则

索引可以简单如一个列 `(a)`，也可以复杂如多个列 `(a,b,c,d)`，即**联合索引**。

- 联合索引，那么key也由多个列组成，同时，索引只能用于查找key是否**存在（相等）**，遇到范围查询 `(>、<、between、like`左匹配)等就**不能进一步匹配**了，后续退化为线性查找。
- **不需要考虑=、in等的顺序**，mysql会自动优化这些条件的顺序，以匹配尽可能多的索引列。

**最左前缀匹配原则**，MySQL会一直向右匹配直到遇到范围查询 `（>,<,BETWEEN,LIKE）`就停止匹配。

---

索引列不能参与计算，尽量保持列“干净”。

- 原因很简单，**B+树中存储的都是数据表中的字段值**，但是进行检索时，需要把所有元素都应用函数才能比较，显然这样的代价太大。

**应该建立起比较好的索引，而不应该依赖于“合并索引”这么一个策略**

- “合并索引”策略简单来讲，就是使用多个单列索引，然后将这些结果用“union或者and”来合并起来

# 锁

锁数据库**隐式**帮我们加了

- 对于 `UPDATE、DELETE、INSERT`语句，**InnoDB**会**自动**给涉及数据集加排他锁（X)
- **MyISAM**在执行查询语句 `SELECT`前，会**自动**给涉及的所有表加**读锁**，在执行更新操作（ `UPDATE、DELETE、INSERT`等）前，会**自动**给涉及的表加**写锁**，这个过程并**不需要用户干预**

---

从锁的粒度分为

表锁

- 开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突概率高，并发度最低

行锁

- 开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高

---

**InnoDB行锁和表锁都支持**！

- InnoDB只有通过**索引条件**检索数据**才使用行级锁**，否则，InnoDB将使用**表锁**

**MyISAM只支持表锁**！

---

## 表锁

**表锁下又分为两种模式**：

- 表读锁（Table Read Lock）
- 表写锁（Table Write Lock）

**读读不阻塞，读写阻塞，写写阻塞**

mysql里边，**写锁是优先于读锁的**！

---

## 行锁（InnoDB）

InnoDB和MyISAM有两个本质的区别：

- InnoDB支持行锁
- InnoDB支持事务

共享锁（S锁）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。

- - 也叫做**读锁**：读锁是**共享**的，多个客户可以**同时读取同一个**资源，但**不允许其他客户修改**。

排他锁（X锁)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。

- - 也叫做**写锁**：写锁是排他的，**写锁会阻塞其他的写锁和读锁**

InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是**表锁**：

- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。
- 意向锁也是数据库隐式帮我们做了，**不需要程序员操心**！

## MVVC

MVCC(Multi-Version Concurrency Control)多版本并发控制，可以简单地认为：**MVCC就是行级锁的一个变种(升级版)**。

- 事务的隔离级别就是**通过锁的机制来实现**，只不过**隐藏了加锁细节**

在**表锁中我们读写是阻塞**的，基于提升并发性能的考虑，**MVCC一般读写是不阻塞的**(所以说MVCC很多情况下避免了加锁的操作)

---

通过一定机制生成一个数据请求**时间点的一致性数据快照（Snapshot)**，并用这个快照来提供一定级别（**语句级或事务级**）的**一致性读取**。从用户的角度来看，好像是**数据库可以提供同一数据的多个版本**。

---

## 隔离级别

> **锁的应用最终导致不同事务的隔离级别**

快照有**两个级别**：

- 语句级

  ​	针对于 `Read committed`隔离级别

- 事务级别

  ​	针对于 `Repeatable read`隔离级别

  ---

- 出现脏读的原因是因为在读的时候**没有加读锁**，导致可以**读取出还没释放锁的记录**。

  ---

- `Readcommitted`过程：

- 事务A读取了记录(生成版本号)
- 事务B修改了记录(此时加了写锁)
- 事务A再读取的时候，**是依据最新的版本号来读取的**(当**事务B执行commit了之后，会生成一个新的版本号)，如果事务B还没有commit，那事务A读取的还是之前版本号的数据。**

---

`Repeatableread`避免不可重复读是**事务级别**的快照！每次读取的都是当前事务的版本，即使被修改了，也只会读取当前事务版本的数据。

- 每开始一个事务，系统版本号都会自动递增

- 事务开始时刻的系统版本号会作为事务的版本号
- InnoDB只查找版本早于当前事务版本的数据行
  - 行的删除要么未定义，要么大于当前事务版本号

MySQL的 `Repeatable read`隔离级别加上GAP间隙锁**已经处理了幻读了**。

## 悲观锁

```sql
select*from xxxx for update

for update相当于加了排它锁(写锁)
```

## 乐观锁

```sql
update A set Name=lisi,version=version+1 where ID=#{id} and version=#{version}

--判断之前查询到的version与现在的数据的version进行比较，同时会更新version字段
```

## 间隙锁GAP

**用范围条件检索数据**而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给**符合范围条件的已有数据记录的索引项加锁**；

对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”

间隙锁只会在 `Repeatableread`隔离级别下使用

---

假如emp表中只有101条记录，其empid的值分别是1,2,...,100,101

`Select * from  emp where empid > 100 for update;`

- InnoDB**不仅**会对符合条件的empid值为101的记录加锁，也会对**empid大于101（这些记录并不存在）的“间隙”加锁**。

## 死锁

- 以**固定的顺序**访问表和行

- **大事务拆小**。大事务更倾向于死锁，如果业务允许，将大事务拆小。
- 在同一个事务中，尽可能做到**一次锁定**所需要的所有资源，减少死锁概率。
- **降低隔离级别**。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。
- **为表添加合理的索引**



# 合并表

合并了多个子表的逻辑表，子表是使用了myisam存储引擎物理的表，合并表使用merge存储引擎，逻辑表和子表的结构完全相同（包括字段、索引等）。

**删除一个合并表，它的子表不会受任何影响，而如果删除其中一个子表则可能会有不同的后果，这要视操作系统而定**

```sql
create table t1( data int not null primary key )engine=myisam;

create table t2( data int not null primary key )engine=myisam;

create table t3( data int not null primary key ) engine=merge union=(t1,t2) insert_method=last;

--insert_method为last，意思就是在最后一张物理表的末尾插入真实数据，这里最后一张真实物理表就是t2。此时我们插入一个数据5会发现：t1没有，t2有。
```

# 分区表

分区表就是把一张表分开，对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成。

（1）水平分区：根据行切分，也就是把记录分开。

（2）垂直分区：根据列切分，也就是把字段分开。

（3）复合分区：水平分区和垂直分区的结合

# 分库分表

## 单库单表的问题

（1）单库太大：数据库里面的表太多，所在服务器磁盘空间装不下，IO次数多CPU忙不过来。

（2）单表太大：一张表的字段太多，数据太多。查询起来困难。

## 主从复制架构

读写分离。将数据库的写操作和读操作进行分离， 使用多个从库副本（Slaver）负责读，使用主库（Master）负责写， 从库从主库同步更新数据，保持数据一致。

主从复制还是单库单表，只不过复制了很多份并进行同步。

## 分库分表

不管是分库还是分表，都有两种切分方式：水平切分和垂直切分。

**1、分表**

垂直分表

- 表中的字段较多，一般将不常用的、 数据较大、长度较长的拆分到“扩展表“。一般情况加表的字段可能有几百列，此时是按照字段进行数竖直切。注意垂直分是列多的情况。

水平分表

- 单表的数据量太大。按照某种规则（RANGE,HASH取模等），切分到多张表里面去。但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。这种情况是不建议使用的，因为数据量是逐渐增加的，当数据量增加到一定的程度还需要再进行切分。比较麻烦。

**2、分库**

垂直分库

- 一个数据库的表太多。此时就会按照一定业务逻辑进行垂直切，比如用户相关的表放在一个数据库里，订单相关的表放在一个数据库里。注意此时不同的数据库应该存放在不同的服务器上，此时磁盘空间、内存、TPS等等都会得到解决。

水平分库

- 水平分库理论上切分起来是比较麻烦的，它是指将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。

---

### 分库分表存在的问题

1、联合查询困难

联合查询不仅困难，而且可以说是不可能，因为两个相关联的表可能会分布在不同的数据库，不同的服务器中。

2、需要支持事务

分库分表后，就需要支持分布式事务了。数据库本身为我们提供了事务管理功能，但是分库分表之后就不适用了。如果我们自己编程协调事务，代码方面就又开始了麻烦。

3、跨库join困难

分库分表后表之间的关联操作将受到限制，我们无法join位于不同分库的表，也无法join分表粒度不同的表， 结果原本一次查询能够完成的业务，可能需要多次查询才能完成。我们可以使用全局表，所有库都拷贝一份。

4、结果合并麻烦

比如我们购买了商品，订单表可能进行了拆分等等，此时结果合并就比较困难。

# MyBatis

![](http://www.mybatis.cn/usr/uploads/2019/10/326517643.png)

![](https://note.youdao.com/yws/api/personal/file/E327C19DCF1A416E9374C2B20812082D?method=download&shareKey=bae6cb792c40238f127d7d370cda0edb)