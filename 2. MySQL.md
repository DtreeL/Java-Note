# SQL

## DDL

(Date Definition Language)数据定义语言：如建库，建表

### 库

创建数据库

```sql
CREATE DATABASE [IF NOT EXISTS] 数据库名;
CREATE DATABASE 数据库名 character set 字符集;
```

查看数据库

```sql
SHOW DATABASES [LIKE "筛选条件"];
show databases;--查看所有数据库
show create database 数据库名;--查看数据库的定义信息
select database();--查看正在使用的数据库
```

修改数据库

```sql
alter database 数据库名 default character set 字符集;
```

使用数据库

```sql
use 数据库名;
```

删除数据库

```sql
drop database 数据库名;
```

### 表(前提是先使用某个数据库)

创建表

```sql
create table 表名(
    --int double varchar()可变字符串 date日期类型，无时分秒
    --primary key设置为主键,auto_increment代表自增
	字段名1 字段类型1 primary key auto_increment，
  
    --unique唯一约束，代表这一列不能出现同名，null没有数据不存在相不相同的问题
    --not null
    --default 默认值
    字段名2 字段类型2 unique，
    ...
    --最后一个结尾没有逗号
    字段名n，字段类型n
)auto_increment=自增的起始值;

--创建的表1结构跟表2一样
create table 表1 like 表2;

添加外键
FOREIGN KEY 字段1 字段2..... REFERENCES 主表 字段1 字段2......
```

查看表

```sql
show tables;

desc 表名;--查看表结构
```

删除表

```sql
drop table 表名;
drop if exist 表名;
```

修改表

```sql
alter table 表名 add 列名 类型;
alter table 表名 modify 列名 新的类型;
alter table 表名 change 旧列名 新列名 类型;
alter table 表名 drop 列名;--删除列

rename table 表名 to 新表名;

alter table 表名 character set 字符集;
alter table 表名 add primary key(字段名)；--修改字段为主键
alter table 表名 auto_increment=起始值;--创建好表后修改起始值
ALTER TABLE 表名 ADD FOREIGN KEY 外键字段名 REFERENCES 主表名 主表字段;
ALTER TABLE 表名 DROP FOREIGN KEY 外键字段名
```

## DML

(Date Manipulation Language)数据操纵语言：记录操作增删改

```sql
--插入
insert into 表名(
	字段名1，字段名2，字段名3，...--不写字段名默认全部
)
values(
	值1，值2，值3，...--值对应不上上面的字段，会使用null，字符型和日期要用引号
);
insert into 表名1(列1，列2) select 列1，列2 from 表名2;--复制表
insert ignore into
	会忽略数据库中已经存在的数据，如果数据库没有数据，就插入新的数据，如果有数据的话就跳过这条数据。
--更新
update 表名 set 列名=值 where 条件表达式;--不写条件为所有修改

--删除，对自增长没有影响
delete from 表名 where 条件表达式;

truncate table 表名;--删除该表再建一空表
```

## DQL

(Data Query Language)数据查询语言

and比or的执行优先级高

```sql
select * from 表名;
select 字段1 as 别名，字段2，... from 表名 as 别名;--显示的时候显示别名
select distinct 字段名 from 表名;--清除字段重复值
select 列名1+固定值/列名2 from 表名;--查询的结果是参与运算后的结果

select 字段 into 表1 from 表2，创建表1，把表2的数据复制给表1


where 条件查询
<>--不等于符号
between 100 and 200 --一个范围内，包括100和200
in(,)
like '张%'--模糊查询，%匹配任意字符（不匹配NULL），_匹配一个字符
is null

逻辑运算符 and > or > not，or是短路运算,not放在前面否定后面的条件

--排序查询,写在where后
order by 字段名1 asc/desc，字段名2 asc/desc，...;--默认asc升序，字段1相同的数据再按照字段2排序
			2,2 -- 按列位置排序
LIMIT 5 -- 限制5行记录
--分页查询
--limit 指定查询结果的行数 
LIMIT 3 OFFSET 3; -- 哪行起的第几行数据，简化成LIMIT 3,3
/*
分页查询的关键在于，首先要确定每页需要显示的结果数量pageSize（这里是3），然后根据当前页的索引pageIndex（从1开始），确定LIMIT和OFFSET应该设定的值：

LIMIT=pageSize；
OFFSET计算公式为pageSize * (pageIndex - 1)。
这样就能正确查询出第N页的记录集。
*/

--聚合函数,对列进行操作，返回列值，会忽略null
max(列名)
min(列名)
avg(列名)
count(列名)--计算这一列有多少条记录
count(ifnull(id,0))--不忽略null

sum(列名)

--分组查询，按字段进行分组
group by --分组列出
Having -- 过滤分组
group by 字段 having 条件;--having分组后再条件过滤

concat(,,) -- 逗号的每一项相当于用+拼接起来
```

```sql
UPPER() -- 转换大写
LOWER（）
LTRIM（）
RTRIM（）--去除列值右边的空格

ABS()
COS()
EXP()
PI()
SQRT()
SIN()
TAN()

union放在两个select语句之间，代表执行两个select语句并把结果合在一起，重复行去除
```



### 多表查询

子查询：把一个select语句（**只能查询单列**）的结果作为数据进行嵌套

- 先执行子查询

等值联结：用where把多个表的查询关系确定 

```java
A表 
	id name
	1  张三
	2  李四
	3  王五

B表
	id  a_id  class
	1   4     班级1
	2   2     班级2
```

内连接：只返回两个表都有，而且id相等的值

```sql
SELECT 字段集 FROM 表1 INNER JOIN 表2 ON 连接条件;

select A.name,B.class from A a  inner join B b on a.id=b.a_id

李四  班级2
```

左连接：返回包括左表所有记录，还有和右表中相等的记录

```sql
SELECT 字段集 FROM 表1 LEFT JOIN 表2 ON 连接条件;

select a.name,b.job from A a  left join B b on a.id=b.A_id

张三 null   李四  班级2   王五  null

返回A表所有的数据，没有在B表匹配的直接用null
```

右连接：返回包括右表所有记录，还有和左表中相等的记录

```java
SELECT 字段集 FROM 表1 RIGHT JOIN 表2 ON 连接条件;
```

![](https://gitee.com/DtreeL/Image-Hosting-Service/raw/master/img/20200516145800.png)

分组查询

```sql
SELECT 字段名 [聚合函数] FROM 表名 GROUP BY 字段名  [ASC | DESC] ;

select name,cout(*) as totle
from stu
group by class_id;
having count(name) > 1;

--查询所有在一个班级的同学姓名和人数,having设置条件
```

正则

| 选项        | 说明                                                      |
| :---------- | :-------------------------------------------------------- |
| ^           | 匹配文本的开始字符，如^a，就会匹配ads、alr、aea等         |
| $           | 匹配文本的结束字符                                        |
| .           | 匹配任何单个字符，如b.t，可以匹配bit、bat、but等等        |
| *           | 匹配0个或者多个在它前面的字符，如f*n。fn、fan、fasardsn等 |
| +           | 匹配前面的字符1次或者多次，如ba+，b后面至少紧跟一个a      |
| [字符集合]  | 匹配字符集任何一个字符，如[ab]，匹配a或者b的一个          |
| [^字符集合] | 匹配不在字符集的任何字符                                  |
| 字符串{n}   | 匹配前面的字符至少n次，如b{3},至少bbbb、bbbbb             |

## DCL

(Data Control Language)数据控制语言：权限设定

电脑上有多个项目的数据库

```sql
--查询用户
use myql;--切换到mysql数据库
select * from user;--查询用户表

--添加删除用户
create user '用户名'@'主机名' identified by '密码';--主机名表示该用户可以在哪个主机登录
drop use '用户名'@'主机名';

--授予/撤销用户权限
show grants for '用户名'@'主机名'；--查询权限
grant 权限列表 on 数据库.表名 to '用户名'@'主机名';--授予权限,通配符权限all 库和表*
revoke 权限列表 on 数据库.表名 to '用户名'@'主机名';--撤销权限
```

## 事务

事务又叫做TCL，全称是transaction control language

**A（原子性Atomicity）：原子性指的是事务是一个不可分割的，要么都执行要么都不执行。**

**C（一致性Consistency）：事务必须使得数据库从一个一致性状态，到另外一个一致性状态。**

**I（隔离性Isolation）：指的是一个事务的执行，不能被其他的事务所干扰。**

**D（持久性Durability）：持久性指的是一个事务一旦提交了之后，对数据库的改变就是永久的。**

隐式的事务很简单，比如我们的insert、delete、update、select这些语句都是隐式的事务。

显示的事务

```sql
步骤一：禁用步骤提交功能
set autocommit = 0；

步骤二：开启一个事务
start transaction；

步骤三：sql语句
update table user set money=500 where name = "张三"；
update table user set money=1500 where name = "李四"；

步骤四：结束事务
commit（提交）或者是rollback（回滚）。如果确定我们的语句没有问题，那么我们就可以commit，如果认为我们的语句有问题，那就rollback。
```

| Isolation Level              | 脏读（Dirty Read） | 不可重复读（Non Repeatable Read） | 幻读（Phantom Read） |
| :--------------------------- | :----------------- | :-------------------------------- | :------------------- |
| Read Uncommitted             | Yes                | Yes                               | Yes                  |
| Read Committed               | -                  | Yes                               | Yes                  |
| Repeatable Read（MySQL默认） | -                  | -                                 | Yes                  |
| Serializable                 | -                  | -                                 | -                    |

- **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。
- **READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。
- **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。
- **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。



InnoDB 存储引擎在 **REPEATABLE-READ（可重读）** 事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server) 是不同的。

- 隔离级别越低，事务请求的锁越少，但InnoDB 存储引擎默认使用 **REPEAaTABLE-READ（可重读）** 并不会有任何性能损失。

---

脏读

- 一个事务会读到另一个事务更新后但未提交的数据，如果读了数据后对方回滚，那么当前事务读到的数据就是脏数据，这就是脏读（Dirty Read），转账显示到帐，回滚后钱消失了

**丢失修改（Lost to modify）:**

- 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。

不可重复读

- 在一个事务内，多次读同一数据，在这个事务还没有结束时，如果另一个事务恰好修改了这个数据，那么，在第一个事务中，两次读取的数据就可能不一致。
- 在一个事务内读取两次同一个数据，竟然不一样

幻读

- 在一个事务中，第一次查询某条记录，发现没有，但是，当试图更新这条不存在的记录时，竟然能成功，并且，再次读取同一条记录，它就神奇地出现了
- 事务B在第3步第一次读取`id=99`的记录时，读到的记录为空，说明不存在`id=99`的记录。随后，事务A在第4步插入了一条`id=99`的记录并提交。事务B在第6步再次读取`id=99`的记录时，读到的记录仍然为空，但是，事务B在第7步试图更新这条不存在的记录时，竟然成功了，并且，事务B在第8步再次读取`id=99`的记录时，记录出现了。
- 可见，幻读就是没有读到的记录，以为不存在，但其实是可以更新成功的，并且，更新成功后，再次读取，就出现了。



## 视图

从每一个班级里面筛选出几个优秀的同学去参加考试。这时候每一个班级就可以当做是一张真实的表，很多班级筛选出来的这些同学就可以临时组成一个班级，这个班级就可以当做一个视图，也就是说，这个班级其实不是真实存在的，当考试过后，这些学生还是各回各家各找各妈。

通常情况下，视图是为了封装一些复杂的操作或者是一些重复的操作。比如说在多个地方使用相同的查询结果，再或者是sql语句比较复杂，封装成视图，下一次直接使用即可。

**创建视图：**

- create view 视图名 as select 字段名称 from 表名……;

**查看视图：**

（1）describe 视图名;

（2）show table status like '视图名'\G;

（3）show create view 视图名;

（4）select * from information_schema.views;

**修改视图：**

- create  view 视图名 as select 字段名称 from 表名……. ;

- alter   view 视图名 as select 字段名称 from 表名……;

**更新视图：**

（1）update 视图名 set 字段名=值;

（2）insert into 表名 values(值，值…);

（3）delete from 视图名 where 字段=值;

**删除视图：**

drop view if exists 视图名;

## 约束

主键约束 primary key

外键约束 reference

唯一约束 unique

检查约束 check（price>0）

- ADD CONSTRAINT CHECK (gender LIKE '[MF]')

## 索引

找一个数据，从头到尾没必要。索引就像是字典的目录

- 主键是排好序的所以按照主键搜索很快，但是其他列不行

```java
CREATE INDEX prod_name_ind
ON Products (prod_name);
```



# JDBC（Java Database Connectivity）

> Java代码并不是直接通过TCP连接去访问数据库，而是通过JDBC接口来访问，而JDBC接口则通过JDBC驱动来实现真正对数据库的访问。

访问某个具体的数据库，我们只需要引入该厂商提供的JDBC驱动，就可以通过JDBC接口来访问

- 我们把某个数据库实现了JDBC接口的jar包称为JDBC驱动。

## Connection

Connection代表一个JDBC连接，它相当于Java程序到数据库的连接（通常是TCP连接）。

- 打开一个Connection时，需要准备URL、用户名和口令，才能成功连接到数据库。

```java
// 获取连接
Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)
```

```java
try (Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)) {
    try (PreparedStatement ps = conn.prepareStatement("SELECT id, grade, name, gender FROM students WHERE gender=? AND grade=?")) {
        ps.setObject(1, "M"); // 注意：索引从1开始
        ps.setObject(2, 3);
        try (ResultSet rs = ps.executeQuery()) {
            while (rs.next()) {
                long id = rs.getLong("id");
                long grade = rs.getLong("grade");
                String name = rs.getString("name");
                String gender = rs.getString("gender");
            }
        }
    }
}
```

| SQL数据类型   | Java数据类型             |
| :------------ | :----------------------- |
| BIT, BOOL     | boolean                  |
| INTEGER       | int                      |
| BIGINT        | long                     |
| REAL          | float                    |
| FLOAT, DOUBLE | double                   |
| CHAR, VARCHAR | String                   |
| DECIMAL       | BigDecimal               |
| DATE          | java.sql.Date, LocalDate |
| TIME          | java.sql.Time, LocalTime |

## JDBC Batch

SQL数据库对SQL语句相同，但只有参数不同的若干语句可以作为batch执行，即批量执行，这种操作有特别优化，速度远远快于循环执行每个SQL。

- 需要对同一个`PreparedStatement`反复设置参数并调用`addBatch()`，这样就相当于给一个SQL加上了多组参数，相当于变成了“多行”SQL。
- 调用的不是`executeUpdate()`，而是`executeBatch()`，因为我们设置了多组参数，相应地，返回结果也是多个`int`值，因此返回类型是`int[]`，循环`int[]`数组即可获取每组参数执行后影响的结果数量。

## JDBC连接池

为了避免频繁地创建和销毁JDBC连接，我们可以通过连接池（Connection Pool）复用已经创建好的连接。

- JDBC连接池有一个标准的接口`javax.sql.DataSource`

常用的JDBC连接池有：

- HikariCP
- C3P0
- BoneCP
- Druid

目前使用最广泛的是HikariCP。

---

语法不同：PreparedStatement可以使用预编译的sql，而Statment只能使用静态的sql

效率不同：PreparedStatement可以使用sql缓存区，效率比Statment高

安全性不同：PreparedStatement可以有效防止sql注入，而Statment不能防止sql注入。

# MySQL逻辑架构

![](https://gitee.com/DtreeL/Image-Hosting-Service/raw/master/img/20200516153022.png)

**连接器：** 身份认证和权限相关(登录 MySQL 的时候)。

**查询缓存:** 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。

**分析器:** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先**看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。**

- **第一步，词法分析**，一条 SQL 语句有多个字符串组成，首先要
  - 提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。
- **第二步，语法分析**，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。

**优化器：** 按照 MySQL 认为最优的方案去执行。

**执行器:** 执行语句，然后从存储引擎返回数据。

## SQL语句的执行过程

### 查询

1. 连接器验证权限相关等
2. 8.0之前的查询缓存，没有则分析器分析
3. 分析器提取SQL关键字看SQL的功能是什么，然后检验语法是否正确
4. 优化器：按照MySQL认为最优的方法优化
5. 执行器：没有权限返回错误信息，有权限调用数据库引擎返回引擎执行结果

### 更新

基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志

1. 先查到需要更新的数据，有缓存也会走缓存
2. 分析器完后，把字段修改，调用引擎接口写入这一行数据，InnoDB把数据存在内存中，同时记录rudo log，此时redo log进入prepare状态，然后告诉执行器，执行完了随时可以提交
3. 执行器接收到通知后，记录bin log，调用引擎接口，提交redo log为提交状态
4. 更新完成

# MySQL如何保证原子操作

MySQL里边还有几种常见的`log`，分别为：

- `undo log`
- `binlog`
- `redo log`

## bin log

无论MySQL使用什么引擎都会产生

**用户检索的出来数据是走搜索引擎的**，所以**数据库的变更，搜索引擎的数据也需要变更**

- 于是，我们就会监听`binlog`的变更，如果`binlog`有变更了，那我们就需要将变更写到对应的数据源。

---

`binlog`记录了数据库表结构和表数据变更，存储着每条变更的`SQL`语句

因为`binlog`记录了数据库表的变更，所以我们可以用`binlog`进行复制（主从复制)和恢复数据。

## redo log

> `redo log`是MySQL的InnoDB引擎所产生的。

Mysql的基本存储结构是**页**(记录都存在页里边)，所以MySQL是先把这条记录所在的**页**找到，然后把该页加载到内存中，将对应记录进行修改。

**如果在内存中把数据改了，还没来得及落磁盘，而此时的数据库挂了怎么办**？每个请求都需要将数据**立马**落磁盘之后，那速度会很慢

- 内存写完了，然后会写一份`redo log`，这份`redo log`记载着这次**在某个页上做了什么修改**。
- 写`redo log`的时候，也会有`buffer`，是先写`buffer`，再真正落到磁盘中的。

---

redo log使用顺序IO（顺序IO比随机IO快非常多）

修改的时候，写完内存了，但数据还没真正写到磁盘的时候，数据库挂了，可以根据`redo log`来对数据进行恢复。因为`redo log`是顺序IO，所以**写入的速度很快**，并且`redo log`记载的是物理变化（xxxx页做了xxx修改），文件的体积很小，**恢复速度很快**。

---

`binlog`记载的是`update/delete/insert`这样的SQL语句，而`redo log`记载的是物理修改的内容（xxxx页修改了xxx）。

`redo log`的作用是为**持久化**而生的。写完内存，如果数据库挂了，那我们可以通过`redo log`来恢复内存还没来得及刷到磁盘的数据，将`redo log`加载到内存里边，那内存就能恢复到挂掉之前的数据了。

---

`redo log`**事务开始**的时候，就开始记录每次的变更信息，而`binlog`是在**事务提交**的时候才记录。

- 写`redo log`失败了，那我们就认为这次事务有问题，回滚，不再写`binlog`
- 写`redo log`成功了，写`binlog`，写`binlog`写一半了，但失败了怎么办？我们还是会对这次的**事务回滚**，将无效的`binlog`给删除（因为`binlog`会影响从库的数据，所以需要做删除操作）
- 写`redo log`和`binlog`都成功了，那这次算是事务才会真正成功。

## 保证redo log与bin log的一致性

- 阶段1：InnoDB`redo log` 写盘，InnoDB 事务进入 `prepare` 状态
- 阶段2：`binlog` 写盘，InooDB 事务进入 `commit` 状态
  - 每个事务`binlog`的末尾，会记录一个 `XID event`，标志着事务是否提交成功，也就是说，恢复过程中，`binlog` 最后一个 XID event 之后的内容都应该被 purge。

## undo log

作用：回滚和多版本控制(MVCC)

在数据修改的时候，不仅记录了`redo log`，还记录`undo log`，如果因为某些原因导致事务失败或回滚了，可以用`undo log`进行回滚魔女娜娜

`undo log`主要存储的也是逻辑日志

`undo log`存储着修改之前的数据，相当于一个**前版本**，MVCC实现的是读写不阻塞，读的时候只要返回前一个版本的数据就行了。

# MySQL变量

## 系统变量

查看：`show global variables;`

**查看某个指定的系统变量**：select @@global.变量名称

- 查看会话变量值只需要global改为session

**为某个变量赋值**

- set global | session 系统变量名 = 新值；

- set @@global | @@session.系统变量名 = 值；

## 自定义变量

用户变量

- 用户变量的作用域是当前会话，也就是说你再新建一个终端或者是命令行窗口就无效了。

```sql
set @用户变量名 = 值
set @用户变量名 := 值
select @用户变量名：=值

--赋值并查看
select 字段 into 自定义变量 from 表名；
```

局部变量

- 作用域就是在定义他的begin end中有效。

```sql
declare 变量名 类型；
declare 变量名 类型 default 默认值；

set @用户变量名 = 值
set @用户变量名 := 值
select @用户变量名：=值
select 字段 into 自定义变量 from 表名；

select 局部变量名;
```

# 存储引擎对比

## MyISAM

| 功能         | MylSAM | MEMORY | InnoDB | Archive |
| :----------- | :----- | :----- | :----- | :------ |
| 存储限制     | 256TB  | RAM    | 64TB   | None    |
| 支持事务     | No     | No     | Yes    | No      |
| 支持全文索引 | Yes    | No     | No     | No      |
| 支持树索引   | Yes    | Yes    | Yes    | No      |
| 支持哈希索引 | No     | Yes    | No     | No      |
| 支持数据缓存 | No     | N/A    | Yes    | No      |
| 支持外键     | No     | No     | Yes    | No      |

总结

- MyISAM不支持事务、哈希索引、数据缓存、外键，但支持全文索引、树索引
- InnoDB不支持全文索引和哈希索引
- 只有MyISAM支持全文检索
- 只有InnoDB支持事务、外键
- 只有MEMORY支持哈希索引

---

使用这个存储引擎，每个MyISAM在磁盘上存储成三个文件。

（1）frm文件：存储表的定义数据

（2）MYD文件：存放表具体记录的数据

（3）MYI文件：存储索引

MYI文件用来存储索引，但仅保存记录所在页的指针，索引的结构是B+树结构

---

1. **是否支持行级锁** : MyISAM 只有表级锁(table-level locking)，而InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。
2. **是否支持事务和崩溃后的安全恢复： MyISAM** 强调的是性能，每次查询具有原子性,其执行速度比InnoDB类型更快，但是不提供事务支持。但是**InnoDB** 提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。

3. **是否支持外键：** MyISAM不支持，而InnoDB支持。

4. **是否支持MVCC** ：仅 InnoDB 支持。应对高并发事务, MVCC比单纯的加锁更高效;MVCC只在 `READ COMMITTED` 和 `REPEATABLE READ` 两个隔离级别下工作;MVCC可以使用 乐观(optimistic)锁 和 悲观(pessimistic)锁来实现;各数据库中MVCC实现并不统一。

校对规则则是指某种字符集下的排序规则



# 索引

索引加快搜索速度（二分查找），因为需要维护索引，所以会降低更新的速度，并且需要**占物理和数据空间**

Mysql支持Hash索引和B+树索引两种

---

MySQL的存储以页为单位

- 页（表）组成一个双向链表，表中的记录组成一个单向链表

记录会生成一个主键的**页目录**，所以使用查找主键使用二分法

- 以**其他列**(非主键)作为搜索条件：只能从最小记录开始**依次遍历单链表中的每条记录**。

---

无优化的sql

- 遍历双向链表，定位到记录所在的页
- 由于不是根据主键查询，只能遍历所在页的单链表了

![](https://gitee.com/DtreeL/Image-Hosting-Service/raw/master/img/20200517123933.png)

底层结构就是**B+树**，B+树作为树的一种实现，能够让我们**很快地**查找出对应的记录

**要维持平衡树，就必须做额外的工作**。正因为这些额外的工作**开销**，导致索引会降低增删改的速度

## 哈希索引

哈希索引就是采用一定的**哈希算法**，把键值换算成新的哈希值，只需一次哈希算法即可**立刻定位到相应的位置，速度非常快**。

- 哈希索引也没办法利用索引完成**排序**
- 不支持**最左匹配原则**
- 在有大量重复键值情况下，哈希索引的效率也是极低的---->**哈希碰撞**问题。
- **不支持范围查询**

## 聚集和非聚集索引

聚集索引就是以**主键**创建的索引

非聚集索引（二级索引）就是以**非主键**创建的索引

- 聚集索引在叶子节点存储的是**表中的数据**
- 非聚集索引在叶子节点存储的是**主键和索引列**
  - 使用非聚集索引查询出数据时，**拿到叶子上的主键再去查到想要查找的数据**。(拿到主键再查找这个过程叫做**回表**)
- **创建多个单列(非聚集)索引的时候，会生成多个索引树**(所以过多创建索引会占用磁盘空间)

覆盖索引就是把要**查询出的列和索引是对应的**，不做回表操作

---

## 最左匹配原则

索引可以简单如一个列 `(a)`，也可以复杂如多个列 `(a,b,c,d)`，即**联合索引**。

- 联合索引，那么key也由多个列组成，同时，索引只能用于查找key是否**存在（相等）**，遇到范围查询 `(>、<、between、like`左匹配)等就**不能进一步匹配**了，后续退化为线性查找。
- **不需要考虑=、in等的顺序**，mysql会自动优化这些条件的顺序，以匹配尽可能多的索引列。

**最左前缀匹配原则**，MySQL会一直向右匹配直到遇到范围查询，联合索引从左到右需要都用到，如果用到第二个没用到第一个，则不会触发索引， `（>,<,BETWEEN,LIKE）`就停止匹配。

---

索引列不能参与计算，尽量保持列“干净”。

- 原因很简单，**B+树中存储的都是数据表中的字段值**，但是进行检索时，需要把所有元素都应用函数才能比较，显然这样的代价太大。

**应该建立起比较好的索引，而不应该依赖于“合并索引”这么一个策略**

- “合并索引”策略简单来讲，就是使用多个单列索引，然后将这些结果用“union或者and”来合并起来

# 锁

锁数据库**隐式**帮我们加了

- 对于 `UPDATE、DELETE、INSERT`语句，**InnoDB**会**自动**给涉及数据集加排他锁（X)
- **MyISAM**在执行查询语句 `SELECT`前，会**自动**给涉及的所有表加**读锁**，在执行更新操作（ `UPDATE、DELETE、INSERT`等）前，会**自动**给涉及的表加**写锁**，这个过程并**不需要用户干预**

---

从锁的粒度分为

表锁

- 开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突概率高，并发度最低

行锁

- 开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高

---

**InnoDB行锁和表锁都支持**！

- InnoDB只有通过**索引条件**检索数据**才使用行级锁**，否则，InnoDB将使用**表锁**

**MyISAM只支持表锁**！



**InnoDB存储引擎的锁的算法有三种：**

- Record lock：单个行记录上的锁
- Gap lock：间隙锁，锁定一个范围，不包括记录本身
  - Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
- Next-key lock：record+gap 锁定一个范围，包含记录本身

innodb对于行的查询使用next-key lock

- 当查询的索引含有唯一属性时，将next-key lock降级为record key

---

## 表锁

**表锁下又分为两种模式**：

- 表读锁（Table Read Lock）
- 表写锁（Table Write Lock）

**读读不阻塞，读写阻塞，写写阻塞**

mysql里边，**写锁是优先于读锁的**！

---

## 行锁（InnoDB）

InnoDB和MyISAM有两个本质的区别：

- InnoDB支持行锁
- InnoDB支持事务

共享锁（S锁）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。

- - 也叫做**读锁**：读锁是**共享**的，多个客户可以**同时读取同一个**资源，但**不允许其他客户修改**。

排他锁（X锁)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。

- - 也叫做**写锁**：写锁是排他的，**写锁会阻塞其他的写锁和读锁**

InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是**表锁**：

- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。
- 意向锁也是数据库隐式帮我们做了，**不需要程序员操心**！

## MVVC

MVCC(Multi-Version Concurrency Control)多版本并发控制，可以简单地认为：**MVCC就是行级锁的一个变种(升级版)**。

- 事务的隔离级别就是**通过锁的机制来实现**，只不过**隐藏了加锁细节**

在**表锁中我们读写是阻塞**的，基于提升并发性能的考虑，**MVCC一般读写是不阻塞的**(所以说MVCC很多情况下避免了加锁的操作)

---

通过一定机制生成一个数据请求**时间点的一致性数据快照（Snapshot)**，并用这个快照来提供一定级别（**语句级或事务级**）的**一致性读取**。从用户的角度来看，好像是**数据库可以提供同一数据的多个版本**。

---

## 隔离级别

> **锁的应用最终导致不同事务的隔离级别**

快照有**两个级别**：

- 语句级

  ​	针对于 `Read committed`隔离级别

- 事务级别

  ​	针对于 `Repeatable read`隔离级别

  ---

- 出现脏读的原因是因为在读的时候**没有加读锁**，导致可以**读取出还没释放锁的记录**。

  ---

- `Readcommitted`过程：

- 事务A读取了记录(生成版本号)
- 事务B修改了记录(此时加了写锁)
- 事务A再读取的时候，**是依据最新的版本号来读取的**(当**事务B执行commit了之后，会生成一个新的版本号)，如果事务B还没有commit，那事务A读取的还是之前版本号的数据。**

---

`Repeatableread`避免不可重复读是**事务级别**的快照！每次读取的都是当前事务的版本，即使被修改了，也只会读取当前事务版本的数据。

- 每开始一个事务，系统版本号都会自动递增

- 事务开始时刻的系统版本号会作为事务的版本号
- InnoDB只查找版本早于当前事务版本的数据行
  - 行的删除要么未定义，要么大于当前事务版本号

MySQL的 `Repeatable read`隔离级别加上GAP间隙锁**已经处理了幻读了**。

## 悲观锁

```sql
select*from xxxx for update

for update相当于加了排它锁(写锁)
```

## 乐观锁

```sql
update A set Name=lisi,version=version+1 where ID=#{id} and version=#{version}

--判断之前查询到的version与现在的数据的version进行比较，同时会更新version字段
```

## 间隙锁GAP

**用范围条件检索数据**而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给**符合范围条件的已有数据记录的索引项加锁**；

对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”

间隙锁只会在 `Repeatableread`隔离级别下使用

---

假如emp表中只有101条记录，其empid的值分别是1,2,...,100,101

`Select * from  emp where empid > 100 for update;`

- InnoDB**不仅**会对符合条件的empid值为101的记录加锁，也会对**empid大于101（这些记录并不存在）的“间隙”加锁**。

## 死锁

- 以**固定的顺序**访问表和行

- **大事务拆小**。大事务更倾向于死锁，如果业务允许，将大事务拆小。
- 在同一个事务中，尽可能做到**一次锁定**所需要的所有资源，减少死锁概率。
- **降低隔离级别**。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。
- **为表添加合理的索引**

# SQL执行很慢的原因

平时正常，偶尔很慢

- redo 写满了，内存不够了
- 拿不到锁

## 一直很慢

没用到索引

- 字段本身没有索引。只能全表扫描，再单表扫描
- 字段有索引，但是没有用到
  1. 索引字段不能参与运算（包括函数），否则不会走索引

# 合并表

合并了多个子表的逻辑表，子表是使用了myisam存储引擎物理的表，合并表使用merge存储引擎，逻辑表和子表的结构完全相同（包括字段、索引等）。

**删除一个合并表，它的子表不会受任何影响，而如果删除其中一个子表则可能会有不同的后果，这要视操作系统而定**

```sql
create table t1( data int not null primary key )engine=myisam;

create table t2( data int not null primary key )engine=myisam;

create table t3( data int not null primary key ) engine=merge union=(t1,t2) insert_method=last;

--insert_method为last，意思就是在最后一张物理表的末尾插入真实数据，这里最后一张真实物理表就是t2。此时我们插入一个数据5会发现：t1没有，t2有。
```

# 分区表

分区表就是把一张表分开，对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成。

（1）水平分区：根据行切分，也就是把记录分开。

（2）垂直分区：根据列切分，也就是把字段分开。

（3）复合分区：水平分区和垂直分区的结合

# 分库分表

## 单库单表的问题

（1）单库太大：数据库里面的表太多，所在服务器磁盘空间装不下，IO次数多CPU忙不过来。

（2）单表太大：一张表的字段太多，数据太多。查询起来困难。

## 主从复制架构

读写分离。将数据库的写操作和读操作进行分离， 使用多个从库副本（Slaver）负责读，使用主库（Master）负责写， 从库从主库同步更新数据，保持数据一致。

主从复制还是单库单表，只不过复制了很多份并进行同步。

## 分库分表

不管是分库还是分表，都有两种切分方式：水平切分和垂直切分。

**1、分表**

垂直分表

- 表中的字段较多，一般将不常用的、 数据较大、长度较长的拆分到“扩展表“。一般情况加表的字段可能有几百列，此时是按照字段进行数竖直切。注意垂直分是列多的情况。

水平分表

- 单表的数据量太大。按照某种规则（RANGE,HASH取模等），切分到多张表里面去。但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。这种情况是不建议使用的，因为数据量是逐渐增加的，当数据量增加到一定的程度还需要再进行切分。比较麻烦。

**2、分库**

垂直分库

- 一个数据库的表太多。此时就会按照一定业务逻辑进行垂直切，比如用户相关的表放在一个数据库里，订单相关的表放在一个数据库里。注意此时不同的数据库应该存放在不同的服务器上，此时磁盘空间、内存、TPS等等都会得到解决。

水平分库

- 水平分库理论上切分起来是比较麻烦的，它是指将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。

---

### 分库分表存在的问题

1、联合查询困难

联合查询不仅困难，而且可以说是不可能，因为两个相关联的表可能会分布在不同的数据库，不同的服务器中。

2、需要支持事务

分库分表后，就需要支持分布式事务了。数据库本身为我们提供了事务管理功能，但是分库分表之后就不适用了。如果我们自己编程协调事务，代码方面就又开始了麻烦。

3、跨库join困难

分库分表后表之间的关联操作将受到限制，我们无法join位于不同分库的表，也无法join分表粒度不同的表， 结果原本一次查询能够完成的业务，可能需要多次查询才能完成。我们可以使用全局表，所有库都拷贝一份。

4、结果合并麻烦

比如我们购买了商品，订单表可能进行了拆分等等，此时结果合并就比较困难。

# MyBatis

环境：MySQL5.7

ORM：把数据库的表和简单Java对象(POJO)的映射关系模型

MyBatis是半自动映射，需要配备配置文件

- MyBatis-Config.xml
  - 指定数据源DataSource，mybaits通过xml反射，所以还需要mapper.xml文件（绑定接口）

![mybatis.png](http://www.mybatis.cn/usr/uploads/2019/10/326517643.png)

SqlSessionFactory

- 创建SqlSession的工厂类，一旦被创建，应该在应用执行期间都存在。在应用运行期间不要重复创建多次，建议使用单例模式，SqlSessionFactory通过SqlSessionFactoryBuilder对象类获得

SqlSession实例来直接执行被映射的SQL语句



执行过程

1. MyBatis通过读取配置文件信息（全局配置文件和映射文件），构造出SqlSessionFactory

   - ==全局配置文件配置了数据源、事务等信息==；

   - ==映射文件配置了SQL执行相关的信息==。Mapper.xml

   - ```java
     // 读取mybatis-config.xml文件
       InputStream inputStream = 
           Resources.getResourceAsStream("mybatis-config.xml");
     
     // 初始化mybatis，创建SqlSessionFactory类的实例
       SqlSessionFactory sqlSessionFactory = 
           new SqlSessionFactoryBuilder().build(inputStream);
     ```

2. 创建SqlSession

   ```java
   // 创建Session实例
           SqlSession session = sqlSessionFactory.openSession();
   ```

   

3. SqlSession本身不能直接操作数据库，通过底层的Executor执行器接口来操作数据库的

   - Executor接口有两个实现类，一个是普通执行器，一个是缓存执行器（默认）

   - Executor执行器要处理的SQL信息是封装到一个底层对象MappedStatement中。

     - 该对象包括：SQL语句、输入参数映射信息、输出结果集映射信息。
     - 其中输入参数和输出结果的映射类型包括Java的简单类型、HashMap集合对象、POJO对象类型。

   - ```java
     // 操作数据库方法二：获得mapper接口的代理对象
             PersonMapper pm = session.getMapper(PersonMapper.class);
     // 直接调用接口的方法，查询id为1的Peson数据
             Person p2 = pm.selectPersonById(1);
     
     增删改需要提交事务
     // 提交事务
             session.commit();
     // 关闭Session
             session.close();
     ```



### 快速上手

1. 创建全局Mybatis配置XML文件

   ```xml
   <?xml version="1.0" encoding="UTF-8" ?>
   <!DOCTYPE configuration
     PUBLIC "-//mybatis.org//DTD Config 3.0//EN"
     "http://mybatis.org/dtd/mybatis-3-config.dtd">
   <configuration>
     <environments default="development">
       <environment id="development">
         <transactionManager type="JDBC"/>
         <dataSource type="POOLED">
           <property name="driver" value="com.mysql.jdbc.Driver"/><!--"com.mysql.jdbc.Driver"-->
           <property name="url" value="jdbc:mysql://localhost:3306/数据库名?useSSL=ture&amp;useUnicode=ture&amp;characterEncoding=UTF-8"/>
           <property name="username" value="root"/><!--”“-->
           <property name="password" value="root"/><!--”“-->
         </dataSource>
       </environment>
     </environments>
       
     <mappers>
       <mapper resource="org/mybatis/example/BlogMapper.xml"/><!--写好的SQL语句映射XML文件注册到全局配置文件中-->
     </mappers>
   </configuration>
   ```

2. 根据配置文件创建SqlSessionFactory实例，这些是写死的，构造成工具类

   ```java
   Public class MybatisUtils{
       private static sqlsessionFactory sqlSessionFactory;
       static{//放在static在加载类的时候就加载配置文件
           try{
   			String resource = "org/mybatis/example/mybatis-config.xml";//改为自己创建的配置文件路径
               
               //获取到sqlSessionFactory就可以创建sqlSession对象了
   			InputStream inputStream = Resources.getResourceAsStream(resource);//
   SqlSessionFactory sqlSessionFactory 
       = new SqlSessionFactoryBuilder().build(inputStream);
           }catch(IOException e){
               e.printStackTrance();
           }
       
           //提供一个方法获得SqlSession对象
       public static Sqlsession getSqlSession(){
           return sqlSessionFactory.openSession();
       }
   }
   ```

3. 创建映射SQL语句XML文件，每一个MapperXML文件都需要在MyBatis全局配置文件中注册

   ```xml
   <?xml version="1.0" encoding="UTF-8" ?>
   <!DOCTYPE mapper
     PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
     "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
   <mapper namespace="org.mybatis.example.BlogMapper"><!--命名为接口的全类名，绑定接口-->
     <select id="selectBlog" resultType="Blog">	<!--id:唯一标识改为接口下的方法名，resultType：返回值类型，查出记录需要封装成的对象类型，全类名-->
       select * from 表名 where id = #{id}	<!--#{id}:传递过来的参数中取出id值-->
     </select>
   </mapper>
   ```

4. 获取SqlSession实例，能直接执行已经映射的SQL语句

   ```java
   //新版接口式编程，使用正确描述每个语句的参数和返回值的接口，传入的接口(只需要方法的声明)与SQLXML文件绑定
   try (SqlSession session = sqlSessionFactory.openSession()) {
       //获取到的SqlSession不会自动提交数据，需要手动提交.commit();方法
       //sqlSessionFactory.openSession(ture);自动提交
     
       BlogMapper mapper = session.getMapper(BlogMapper.class);//获取接口的实现类对象，会为接口自动创建一个代理对象，代理对象执行增删改查
     
       Blog blog = mapper.selectBlog(101);//调用接口的方法
   }
   
   //旧版
   try (SqlSession session = sqlSessionFactory.openSession()) {
       //openSession方法获得SqlSession对象，一个SqlSession就是和数据库的一次对话，用完需要关闭
     
       Blog blog = (Blog) session.selectOne("org.mybatis.example.BlogMapper.selectBlog", 101);//返回Object对象，强转成需要的对象
   }
   
   session.selectOne(String statement, Object parameter);
   //statement:匹配要使用的语句的唯一标识符，XML文件映射SQL语句唯一id标识确定执行的SQL，加上命名空间确定唯一性
   //parameter:传递给语句的参数对象
   ```

### 配置解析

configuration（配置）

- properties（属性：定义配置外在化）

  ```xml
  <properties resource="org/mybatis/example/config.properties"><!--引入外部配置文件-->
       
  <property name="driver" value="${driver}"/><!--引入了外部配置文件后就可以用${}直接取得配置文件的参数-->
  ```

  

- settings（设置：定义MyBatis的一些全局性设置）

- typeAliases（类型别名：为一些类定义别名）

- typeHandlers（类型处理器：定义Java类型与数据库中的数据类型之间的转换关系）

- objectFactory（对象工厂）

- plugins（插件：插件可以修改mybatis的内部运行规则）

  - 通用Mapper
  - Mybatis-Plus

- environments（环境配置）

  - environment（环境变量：多数据源）
  - transactionManager（事务管理器）
  - dataSource（数据源）

- databaseIdProvider（数据库厂商标识）

- mappers（映射器）

### ResultMap

```xml
<resultMap id="userResultMap" type="User">//resultMap的类型时User，然后把属性跟字段名对应上
  <id property="id" column="user_id" />
  <result property="username" column="user_name"/>
  <result property="password" column="hashed_password"/>
</resultMap>

<select id="selectUsers" resultMap="userResultMap">//找userResultMap
  select user_id, user_name, hashed_password
  from some_table
  where id = #{id}
</select>
```

### 日志

```xml
1.<settings>
  <setting name="logImpl" value="LOG4J"/>
</settings>

2.导入依赖
```

创建LOG4J配置文件

```properties
### 配置根将等级为DEBUG的日志信息输出到console，file这两个目的地###
log4j.rootLogger = debug,console,file

### 设置输出sql的级别，其中logger后面的内容全部为jar包中所包含的包名 ###
log4j.logger.org.mybatis=dubug
log4j.logger.java.sql=dubug
log4j.logger.java.sql.Statement=dubug
log4j.logger.java.sql.PreparedStatement=dubug
log4j.logger.java.sql.ResultSet=dubug

### 配置输出到控制台 ###
log4j.appender.console = org.apache.log4j.ConsoleAppender
log4j.appender.console.Target = System.out
log4j.appender.console.layout = org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern =  %d{ABSOLUTE} %5p %c{ 1 }:%L - %m%n

### 配置输出到文件 ###
log4j.appender.file = org.apache.log4j.RollingFileAppender
log4j.appender.file.File = logs/log.log
log4j.appender.file.MaxFileSize = 10mb
log4j.appender.file.Threshold = DEBUG
log4j.appender.file.layout = org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss}  [ %t:%r ] - [ %p ]  %m%n
```

多对一

```xml
<select id = "getStudent" resultMap="StudentTeacher">
	select s.id sid, s.name, sname, t.name tname
    frome student s.teacher t
    where s.tid = t.id;
</select>

<resultMap id = "StudentTeacher" type = "Student">
	<reslut property = "id" column = "sid"/>
	<reslut property = "name" column = "sname"/>
    <association property = "teacher" javaType = "Teacher">
        <reslut property = "name" column = "tname"/>
    </association>
</resultMap>
```

一对多

```xml
<mapper namespace="com.kuang.mapper.TeacherMapper">
    <!--
    思路:
        1. 从学生表和老师表中查出学生id，学生姓名，老师姓名
        2. 对查询出来的操作做结果集映射
            1. 集合的话，使用collection！
                JavaType和ofType都是用来指定对象类型的
                JavaType是用来指定pojo中属性的类型
                ofType指定的是映射到list集合属性中pojo的类型。
    -->
    <select id="getTeacher" resultMap="TeacherStudent">
        select s.id sid, s.name sname , t.name tname, t.id tid
        from student s,teacher t
        where s.tid = t.id and t.id=#{id}
    </select>

    <resultMap id="TeacherStudent" type="Teacher">
        <result  property="name" column="tname"/>
        <collection property="students" ofType="Student">
            <result property="id" column="sid" />
            <result property="name" column="sname" />
            <result property="tid" column="tid" />
        </collection>
    </resultMap>
</mapper>
```



### 动态SQL

根据不同的条件生成不同的SQL语句

```xml
//if标签，如果没有传入“title”，那么所有处于“ACTIVE”状态的BLOG都会返回；反之若传入了“title”，那么就会对“title”一列进行模糊查找并返回 BLOG 结果
<select id="findActiveBlogLike"
     resultType="Blog">
  SELECT * FROM BLOG WHERE state = ‘ACTIVE’
  <if test="title != null">
    AND title like #{title}
  </if>
  <if test="author != null and author.name != null">
    AND author_name like #{author.name} <!--如果查询出来的结果有作者而且有作者名字，就追加条件继查询-->
  </if>
</select>

choose，when，otherwise
<select id="findActiveBlogLike"
     resultType="Blog">
  SELECT * FROM BLOG WHERE state = ‘ACTIVE’
  <choose>
    <when test="title != null">
      AND title like #{title}
    </when>
    <when test="author != null and author.name != null">
      AND author_name like #{author.name}
    </when>
    <otherwise>
      AND featured = 1
    </otherwise>
  </choose>
</select>
```

### 缓存

放在内存中的临时数据，提高查询效率，解决高并发系统问题

本地缓存（local cache）

- 每当一个新 session 被创建，MyBatis 就会创建一个与之相关联的本地缓存。任何在 session 执行过的查询语句本身都会被保存在本地缓存中
- 相同的查询语句和相同的参数所产生的更改就不会二度影响数据库了。本地缓存会被增删改、提交事务、关闭事务以及关闭 session 所清空。
- 一级缓存相当于一个map

二级缓存（second level cache）

- 启用全局的二级缓存，只需要在你的 SQL 映射文件中添加一行：

  ```xml
  <cache/>
  
  //设置属性
  <cache
    eviction="FIFO"
    flushInterval="60000" //刷新间隔
    size="512"	//引用数目
    readOnly="true"/>
  
  //显性
  .<settings>
    <setting name="cacheEnable" value="ture"/> //默认值是ture，但是写出来告诉别人开启了缓存
  </settings>
  ```

  ![](https://raw.githubusercontent.com/DtreeL/Image-Hosting-Service/master/image-20200207211728943.png)

  

![](http://www.mybatis.cn/usr/uploads/2019/10/326517643.png)

![](https://note.youdao.com/yws/api/personal/file/E327C19DCF1A416E9374C2B20812082D?method=download&shareKey=bae6cb792c40238f127d7d370cda0edb)

## 面试题

### #{}和${}的区别

${}：静态文本替换

#{}：sql中的占位符，会把sql中的#{}用？代替，执行SQL前使用PreparedStatement参数设置方法给按顺序占位符设置值

### Xml 映射文件中,除了常见的 select|insert|updae|delete 标签之外,还有哪些标签

`<resultMap>`、`<parameterMap>`、`<sql>`、`<include>`、`<selectKey>`，

加上动态 sql 的 9 个标签，`trim|where|set|foreach|if|choose|when|otherwise|bind`等

### xml与DAO接口对应，DAO接口的工作原理是什么

接口的全限名，就是映射文件中的 namespace 的值

接口的方法名，就是映射文件中`MappedStatement`的 id 值

接口方法内的参数，就是传递给 sql 的参数

`Mapper`接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为 key 值，可唯一定位一个`MappedStatement`

- 工作原理是 JDK 动态代理，代理对象 proxy 会拦截接口方法，转而执行`MappedStatement`所代表的 sql，然后将 sql 执行结果返回。

Hibernate 属于全自动 ORM 映射工具，**使用 Hibernate 查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。**

- 而 Mybatis 在查询关联对象或关联集合对象时，需要手动编写 sql 来完成，所以，称之为半自动 ORM 映射工具。